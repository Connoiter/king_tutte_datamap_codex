{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# codex__set_up_king_tutte_on_colab.ipynb\n",
        "\n",
        "<div>\n",
        "<img src=\"https://connoiter.com/images/tutte/king_tutte_on_colab.transparent_bg.png\" align=\"left\" width=\"200px\"/>\n",
        "\n",
        "The primary value of this King Tutte Datamap Codex is in the corralling of pre-existing example datamap code to run on Google's Colab, a free Jupyter notebook service.\n",
        "\n",
        "This notebook, set_up_king_tutte_on_colab.ipynb, is part of [the King Tutte Datamap Codex repo](https://github.com/Connoiter/king_tutte_datamap_codex). These Codex notebooks run on Colab, which is pretty much the main value of this Codex work: curate and package pre-existing datamap example code and set it up to run out of the box on Colab. As such, this Jupyter Book consists of King Tutte datamap pipelines running on Google's Colab.\n",
        "</div>\n",
        "<br/>\n",
        "\n",
        "## Pedigree\n",
        "\n",
        "This notebook was started from scratch for the Codex project.\n",
        "\n",
        "## What this notebook does\n",
        "\n",
        "We want to run Jupyter notebooks on Colab for free with a GPU. Here are gathered together all the set up hassles related to doing so.\n",
        "1. Google auth\n",
        "2. You have to explicitly ask for a GPU\n",
        "3. Models are downloaded from Hugging Face so we need to set up a key for that as a Colab secret.\n",
        "4. You might want to log-in to GitHub as well if you want to save changes to a notebook on GitHub, under version control.\n"
      ],
      "metadata": {
        "id": "Ny7grsE8RgHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google auth\n",
        "\n",
        "You have to be logged in to a Google account to run anything on Colab.\n",
        "\n",
        "To test if you are logging in to Google, click on `Run all`. If you are not logged in, you will get a pop-up dialog saying, \"**Google sign-in required** You must be logged in with a Google Account to continue.\" If the cells do run, then you're all set on this front."
      ],
      "metadata": {
        "id": "yBv2KOH7RHtS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face auth\n",
        "\n",
        "Models are downloaded from Hugging Face. Some of them are gated, that is you have to click a button agreeing to the open weights model license written by valuable lawyers at large corporations. The follow HF_TOKEN secret is expected to contain one's Hugging Face API key token. Get one at https://huggingface.co/settings/tokens.\n",
        "\n",
        "Here are some articles that walk you through the manual set-up process:\n",
        "- [Configure Your Hugging Face Access Token in Colab Environment](https://pyimagesearch.com/2025/04/04/configure-your-hugging-face-access-token-in-colab-environment/)\n"
      ],
      "metadata": {
        "id": "DTZdarARRyej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F088vKgKRWmf",
        "outputId": "e1f6994e-6072-472e-dd16-97444c6fd306"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): "
          ]
        }
      ],
      "source": [
        "# If auth, then why need secret?\n",
        "# How about look for HF_TOKEN, if HF_TOKEN not found only then: hf auth login\n",
        "!hf auth login"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4518da8",
        "outputId": "c7ae596f-ac01-4e69-9dac-5897f1f914c6"
      },
      "source": [
        "# Test if HF_TOKEN exists\n",
        "# TODO: If auth'd, then why need secret?\n",
        "# How about look for HF_TOKEN, if HF_TOKEN not found only then: hf auth login\n",
        "from google.colab import userdata\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "if hf_token:\n",
        "    print(\"This notebook has detected that the HF_TOKEN Colab secret has been set.\")\n",
        "else:\n",
        "    print(\"HF_TOKEN secret is not set, or access to it has not been granted.\")\n",
        "    !hf auth login"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This notebook has detected that the HF_TOKEN Colab secret has been set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting a GPU\n",
        "\n",
        "Note: Colab instantiates a new VM for each notebook. So even if in this notebook a GPU is requested, that same GPU allocation will not carry over to other notebooks. Normally, each notebook, once loaded, needs to request a GPU (although there do seem to be times where Colab will auo-allocate a GPU if useful. Dunno, not fully clear yet.)\n",
        "\n",
        "Here's a good 2025 writeup: [How to use gpu in google colab?](https://www.geeksforgeeks.org/python/how-to-use-gpu-in-google-colab/)\n"
      ],
      "metadata": {
        "id": "xol-y9rwgb4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  print(\"GPU is available\")\n",
        "else:\n",
        "  print(\"GPU is not available\")"
      ],
      "metadata": {
        "id": "8N1jnLN7Ha74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How to list allocated GPU:\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "mKAN8fkapxhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the free tier of Colab, each user can have only one runtime at a time. So, if you start up a runtime for one notebook, before you can start up another notebook's runtime the first one will have to be disconnected first, on the free tier."
      ],
      "metadata": {
        "id": "nKbiTXEqqgxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Terminate the Session\n",
        "\n",
        "To free up all GPU resources and avoid hitting usage limits when you are finished with your work, in the top-right corner of the Colab interface, click the `RAM/Disk usage` widget (or the small down arrow next to it).\n",
        "Select `Disconnect and delete runtime` from the menu. This action completely ends the virtual machine session assigned to you, returning all resources to the pool."
      ],
      "metadata": {
        "id": "uWaRBJyiB04L"
      }
    }
  ]
}